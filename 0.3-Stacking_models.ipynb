{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBClassifier \n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, RandomizedSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from src.features.build_features import MostFrequentImputer, load_data, add_bucket, set_title\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data \n",
    "train_data = load_data(\"train.csv\")\n",
    "y_train = train_data[\"Survived\"]\n",
    "\n",
    "# test data\n",
    "test_data = load_data(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "relatives = ['SibSp' ,'Parch']\n",
    "\n",
    "def add_columns(df):\n",
    "    df['family'] = df[relatives].sum(axis=1)\n",
    "    df['traveling_alone'] = np.where(df['family']==0,1,0)\n",
    "    df['Sex'] = np.where(df['Sex']=='female',0,1)\n",
    "    df['Age_Bucket'] = add_bucket(df['Age'], bins=6)\n",
    "    df['Fare_Bucket'] = add_bucket(df['Fare'], bins=6)\n",
    "    df['Title'] = df['Name'].apply(set_title)\n",
    "    df['name_length'] = df['Name'].apply(len)\n",
    "    df['Cabin'] = df['Cabin'].apply(lambda x: 0 if type(x) == float else 1)\n",
    "    return df\n",
    "\n",
    "\n",
    "train_data = add_columns(train_data)\n",
    "test_data = add_columns(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical pipeline\n",
    "num_pipeline = Pipeline([ (\"imputer\", SimpleImputer(strategy=\"median\")) ])\n",
    "# categorical pipeline \n",
    "cat_pipeline = Pipeline([\n",
    "        (\"imputer\", MostFrequentImputer()),\n",
    "        (\"cat_encoder\", OneHotEncoder(sparse=False)),\n",
    "    ])\n",
    "\n",
    "# Full pipeline \n",
    "cat_attribs = [\"Pclass\", 'Embarked',  'Age_Bucket', 'Fare_Bucket', 'Title',]\n",
    "num_attribs = [ \"family\", 'name_length',  'traveling_alone', 'Cabin', 'Sex', 'Age', 'Fare']\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_attribs),\n",
    "        (\"cat\", cat_pipeline, cat_attribs),\n",
    "    ])\n",
    "\n",
    "X_train = full_pipeline.fit_transform(train_data)\n",
    "X_test = full_pipeline.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into fifths, with the first 4/5ths train the models, use the remaining 1/5 of data to generate predictions. This predictions will be used as inputs for the second layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 29)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Stage 1 models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_clf = LogisticRegression()\n",
    "param_distribs = {\n",
    "        'class_weight': [None, 'balanced'],\n",
    "        'penalty': ['l1', 'l2'], \n",
    "        'C': np.logspace(-20, 20, 10000), \n",
    "        'solver' : [ 'liblinear']\n",
    "    }\n",
    "\n",
    "rnd_search = RandomizedSearchCV(log_clf , param_distributions=param_distribs,\n",
    "                                n_iter=10, cv=5, scoring='neg_mean_squared_error', random_state=42)\n",
    "rnd_search.fit(X_train, y_train)\n",
    "# rename classifier \n",
    "log_clf = rnd_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8249158249158249"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    " log_clf.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest_clf = RandomForestClassifier()\n",
    "\n",
    "param_distribs = {\n",
    "        'n_estimators': randint(low=1, high=500),\n",
    "        'max_features': randint(low=1, high=10),\n",
    "    }\n",
    "\n",
    "rnd_search = RandomizedSearchCV(forest_clf , param_distributions=param_distribs,\n",
    "                                n_iter=10, cv=5, scoring='neg_mean_squared_error', random_state=42)\n",
    "rnd_search.fit(X_train, y_train)\n",
    "# rename classifier \n",
    "forest_clf = rnd_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9966329966329966"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_clf = GradientBoostingClassifier()\n",
    "\n",
    "\n",
    "param_distribs = {\n",
    "        'n_estimators': randint(low=1, high=500),\n",
    "        'max_features': randint(low=1, high=10),\n",
    "    }\n",
    "\n",
    "rnd_search = RandomizedSearchCV(gb_clf , param_distributions=param_distribs,\n",
    "                                n_iter=10, cv=5, scoring='neg_mean_squared_error', random_state=42)\n",
    "rnd_search.fit(X_train, y_train)\n",
    "# rename classifier \n",
    "gb_clf = rnd_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.941638608305275"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column \n",
    "X_stage2_data= np.c_[ log_clf.predict_proba(X_train)[:,1], forest_clf.predict_proba(X_train)[:,1],gb_clf.predict_proba(X_train)[:,1] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train stage 2 model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "\n",
    "xgb_clf = XGBClassifier(nthreads=-1)  \n",
    "\n",
    "\n",
    "one_to_left = st.beta(10, 1)  \n",
    "from_zero_positive = st.expon(0, 50)\n",
    "\n",
    "params = {  \n",
    "    \"n_estimators\": randint(low=1, high=500),\n",
    "     'max_features': randint(low=1, high=10),\n",
    "    \"max_depth\": st.randint(3, 40),\n",
    "    \"learning_rate\": st.uniform(0.05, 0.4),\n",
    "    \"colsample_bytree\": one_to_left,\n",
    "    \"subsample\": one_to_left,\n",
    "    \"gamma\": st.uniform(0, 10),\n",
    "    'reg_alpha': from_zero_positive,\n",
    "    \"min_child_weight\": from_zero_positive,\n",
    "}\n",
    "\n",
    "rnd_search = RandomizedSearchCV(xgb_clf , param_distributions=param_distribs,\n",
    "                                n_iter=10, cv=5, scoring='neg_mean_squared_error', random_state=42)\n",
    "rnd_search.fit(X_stage2_data, y_train)\n",
    "# rename classifier \n",
    "xgb_clf = rnd_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9966329966329966"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf.score(X_stage2_data, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_stage2_test= np.c_[ log_clf.predict_proba(X_test)[:,1], forest_clf.predict_proba(X_test)[:,1],gb_clf.predict_proba(X_test)[:,1] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['Survived'] = xgb_clf.predict(X_stage2_test)\n",
    "submission = test_data[['PassengerId', 'Survived']]\n",
    "# save\n",
    "submission.to_csv(path_or_buf = 'data/processed/submissions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
